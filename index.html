<!DOCTYPE html>
<html lang="en">
<head>
  <title>Olga Diamanti</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- <meta name="author" content="owwwlab.com"> -->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <link rel="shortcut icon" href="../favicon.ico">

  <!--CSS styles-->
  <link rel="stylesheet" href="css/bootstrap.css">
  <link rel="stylesheet" href="css/font-awesome.min.css">
  <link rel="stylesheet" href="css/perfect-scrollbar-0.4.5.min.css">
  <link rel="stylesheet" href="css/magnific-popup.css">
  <link rel="stylesheet" href="css/style.css">
  <link id="theme-style" rel="stylesheet" href="css/styles/default.css">


  <!--/CSS styles-->
  <!--Javascript files-->
  <script type="text/javascript" src="js/jquery-1.10.2.js"></script>
  <script type="text/javascript" src="js/TweenMax.min.js"></script>
  <script type="text/javascript" src="js/jquery.touchSwipe.min.js"></script>
  <script type="text/javascript" src="js/jquery.carouFredSel-6.2.1-packed.js"></script>

  <script type="text/javascript" src="js/modernizr.custom.63321.js"></script>
  <script type="text/javascript" src="js/jquery.dropdownit.js"></script>

  <script type="text/javascript" src="js/jquery.stellar.min.js"></script>
  <script type="text/javascript" src="js/ScrollToPlugin.min.js"></script>

  <script type="text/javascript" src="js/bootstrap.min.js"></script>

  <script type="text/javascript" src="js/jquery.mixitup.min.js"></script>

  <script type="text/javascript" src="js/masonry.min.js"></script>

  <script type="text/javascript" src="js/perfect-scrollbar-0.4.5.with-mousewheel.min.js"></script>

  <script type="text/javascript" src="js/magnific-popup.js"></script>
  <script type="text/javascript" src="js/custom.js"></script>

  <!--/Javascript files-->

</head>
<body>

  <div id="wrapper">
    <a href="#sidebar" class="mobilemenu"><i class="icon-reorder"></i></a>

    <div id="sidebar">
      <div id="main-nav">
        <div id="nav-container">
          <div id="profile" class="clearfix">
            <div class="portrate hidden-xs"></div>
            <div class="title">
              <h2>Olga Diamanti</h2>
              <h3>Assistant Professor</h3>
              <h3>Department of Mathematics</h3>
              <h3>TU Graz, Austria</h3>
            </div>

          </div>
          <ul id="navigation">
            <li>
              <a href="#biography">
                <div class="icon icon-user"></div>
                <div class="text">About Me</div>
              </a>
            </li>

            <!-- <li>
            <a href="#research">
            <div class="icon icon-book"></div>
            <div class="text">Research</div>
          </a>
        </li> -->

        <li>
          <a href="#publications">
            <div class="icon icon-edit"></div>
            <div class="text">Publications</div>
          </a>
        </li>

        <li>
          <a href="#teaching">
            <div class="icon icon-time"></div>
            <div class="text">Teaching</div>
          </a>
        </li>

    <!-- <li>
    <a href="#gallery">
    <div class="icon icon-picture"></div>
    <div class="text">Gallery</div>
  </a>
</li> -->

<li>
  <a href="#contact">
    <div class="icon icon-calendar"></div>
    <div class="text">Contact</div>
  </a>
</li>

<li class="external">
  <a href="https://www.dropbox.com/scl/fi/uy2dj7is57gt2hx7exizi/resume_Olga.pdf?rlkey=k6q3g09daym4be7iaf6293qbj&dl=0">
    <div class="icon icon-download-alt"></div>
    <div class="text">Resume</div>
  </a>
</li>
</ul>
</div>
</div>

<!-- <div class="social-icons">
<ul>
<li><a href="#"><i class="icon-facebook"></i></a></li>
<li><a href="#"><i class="icon-twitter"></i></a></li>
<li><a href="#"><i class="icon-linkedin"></i></a></li>
</ul>
</div> -->
</div>

<div id="main">

  <div id="biography" class="page home" data-pos="home">
    <div class="pageheader">
      <div class="headercontent">
        <div class="section-container">

          <div class="row">
            <div class="col-sm-2 visible-sm"></div>
            <!-- <div class="col-sm-8 col-md-5">
            <div class="biothumb">
            <img alt="image" src="img/personal/personal-big.png" class="img-responsive">
            <div class="overlay">

            <h1 class="">Olga Diamanti</h1>
            <ul class="list-unstyled">
            <li>Principal AI Researcher</li>
            <li>Machine Intelligence Group</li>
            <li>Autodesk Research</li>
          </ul>
        </div>


      </div>

    </div> -->
    <div class="clearfix visible-sm visible-xs"></div>
    <div class="col-sm-12 col-md-7">
      <h3 class="title">Bio</h3>

      <img alt="image" src="img/personal/personal-big.jpg" width="200"align="right"  style="padding:5px 5px 0px 15px;">

      <p> I am an Assistant Professor at the <a href="http://www.geometrie.tugraz.at/"> Institute for Geometry </a> of the Department of Mathematics at TU Graz, Austria</a>.  </p>

      <p> My research background is in geometric modeling, computer graphics, and computer vision. Prior to joining TU Graz, I was a postdoctoral mathematics researcher at the TU Berlin, with the <a href="https://www.math.tu-berlin.de/arbeitsgruppen/ag_geometrie_und_mathematische_physik/geometrie_und_mathematische_physik//">Institute for Geometry and Mathematical Physics</a>. I have worked at Autodesk Research, San Francisco as a principal AI researcher with the <a href="https://www.autodeskresearch.com/groups/machine-intelligence">Machine Intelligence Lab</a>, and at Stanford University as a postdoctoral CS researcher with the <a href="https://geometry.stanford.edu/">Geometric Computing Lab</a>. My PhD was with the <a href="https://www.igl.ethz.ch">Interactive Geometry Lab</a> of the CS department at ETH Zurich, Switzerland. I have a Master's in CS from ETH Zurich, having worked with the <a href="https://cvg.ethz.ch/">Computer Vision and Geometry Group</a>. My undergraduate (Diploma) work was with the <a href="http://cvsp.cs.ntua.gr/">Computer Vision and Signal Processing Group</a> at the National Technical University of Athens, Greece. I've been an intern for the <a href="https://www.adobe.com/technology.html">Adobe Research Labs</a> in Cambridge MA, and <a href="https://www.disneyresearch.com/research-labs/disney-research-zurich/">Disney Research Zurich</a>. </p>

      <!-- <p> My current research interests lie at the intersection between geometry, machine learning and computational design. I have worked in projects involving learning from large shape collections for object detection and generation, dynamic scene understanding from RGBD sensing, and 3D reconstruction, as well as topics in surface modeling, mesh generation, shape mappings, image synthesis and computational fabrication. </p> -->
      <p> My current research interests lie in applied geometry, somewhere between geometry processing, (discrete) differential geometry, projective geometry, shape modeling/analysis for computer graphics and computational design. I have however also worked in various topics involving shape analysis, meshing, discrete surface maps and parameterization, image synthesis and computational fabrication, and have also been active in projects in geometric machine learning for object detection and generation, dynamic scene understanding from RGBD sensing, and 3D reconstruction. </p>


    </div>

  </div>
</div>
</div>
</div>

<!-- <div class="pagecontents">
<div class="section color-1">
<div class="section-container">
<div class="row">
<div class="col-md-5 col-md-offset-1">
<div class="title text-center">
<h3>Academic Positions</h3>
</div>
<ul class="ul-dates">
<li>
<div class="dates">
<span>Present</span>
<span>2005</span>
</div>
<div class="content">
<h4>General Atlantic Professor</h4>
<p><em>Stanford University</em>, Graduate School of Business</p>
</div>
</li>
<li>
<div class="dates">
<span>2005</span>
<span>2004</span>
</div>
<div class="content">
<h4>Full Professor</h4>
<p><em>Stanford University</em>, Graduate School of Business</p>
</div>
</li>
<li>
<div class="dates">
<span>2004</span>
<span>2001</span>
</div>
<div class="content">
<h4>Assistant Professor</h4>
<p><em>UCLA</em>, Anderson Graduate School of Management</p>
</div>
</li>
<li>
<div class="dates">
<span>2001</span>
<span>1999</span>
</div>
<div class="content">
<h4>Visiting Assistant Professor</h4>
<p><em>Columbia University</em>, Graduate School of Business</p>
</div>
</li>
</ul>
</div>
<div class="col-md-5">
<div class="title text-center">
<h3>Education & Training</h3>
</div>
<ul class="ul-card">
<li>
<div class="dy">
<span class="degree">Ph.D.</span>
<span class="year">1995</span>
</div>
<div class="description">
<p class="waht">Ph.D. in Marketing</p>
<p class="where">Stanford University Graduate School of Business</p>
</div>
</li>
<li>
<div class="dy">
<span class="degree">M.B.A.</span><span class="year">1993</span>
</div>
<div class="description">
<p class="waht">Master of Business Administration</p>
<p class="where">Boston University</p>
</div>
</li>
<li>
<div class="dy">
<span class="degree">B.A.</span><span class="year">1989</span>
</div>
<div class="description">
<p class="waht">Bachelor of Arts in Psychology</p>
<p class="where">University of California, Berkeley</p>
</div>
</li>

</ul>

</div>
</div>
</div>

</div>

<div class="section color-2">
<div class="section-container">
<div class="row">
<div class="col-md-10 col-md-offset-1">
<div class="title text-center">
<h3>Honors, Awards and Grants</h3>
</div>
<ul class="timeline">

<li class="open">
<div class="date">SCP 2014</div>
<div class="circle"></div>
<div class="data">
<div class="subject">Distinguished Scientific Achievement Award</div>
<div class="text row">
<div class="col-md-2">
<img alt="image" class="thumbnail img-responsive" src="img/personal/awards100x100.png" >
</div>
<div class="col-md-10">
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed egestas dapibus lectus non dignissim. Pellentesque auctor ornare urna, volutpat condimentum quam porttitor at. Vestibulum tincidunt diam in eros aliquam luctus. Donec sagittis a purus a porttitor. Sed non feugiat enim. Donec eget metus erat. Vivamus sed consequat orci. Aenean commodo lectus sed purus auctor ullamcorper.
</div>
</div>
</div>
</li>
<li>
<div class="date">2012-2013</div>
<div class="circle"></div>
<div class="data">
<div class="subject">Ormond Family Faculty Fellow</div>
<div class="text row">
<div class="col-md-2">
<img alt="image" class="thumbnail img-responsive" src="img/personal/awards100x100.png" >
</div>
<div class="col-md-10">
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed egestas dapibus lectus non dignissim. Pellentesque auctor ornare urna, volutpat condimentum quam porttitor at. Vestibulum tincidunt diam in eros aliquam luctus. Donec sagittis a purus a porttitor. Sed non feugiat enim. Donec eget metus erat. Vivamus sed consequat orci. Aenean commodo lectus sed purus auctor ullamcorper.
</div>
</div>
</div>
</li>
<li>
<div class="date">June 2011</div>
<div class="circle"></div>
<div class="data">
<div class="subject">Nautilus Silver Award for Dragonfly Effect</div>
<div class="text row">
<div class="col-md-2">
<img alt="image" class="thumbnail img-responsive" src="img/personal/awards100x100.png" >
</div>
<div class="col-md-10">
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed egestas dapibus lectus non dignissim. Pellentesque auctor ornare urna, volutpat condimentum quam porttitor at. Vestibulum tincidunt diam in eros aliquam luctus. Donec sagittis a purus a porttitor. Sed non feugiat enim. Donec eget metus erat. Vivamus sed consequat orci. Aenean commodo lectus sed purus auctor ullamcorper.
</div>
</div>
</div>
</li>
<li>
<div class="date">2000 - 2003</div>
<div class="circle"></div>
<div class="data">
<div class="subject">Hong Kong Science International Research Grant</div>
<div class="text row">
<div class="col-md-2">
<img alt="image" class="thumbnail img-responsive" src="img/personal/awards100x100.png" >
</div>
<div class="col-md-10">
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed egestas dapibus lectus non dignissim. Pellentesque auctor ornare urna, volutpat condimentum quam porttitor at. Vestibulum tincidunt diam in eros aliquam luctus. Donec sagittis a purus a porttitor. Sed non feugiat enim. Donec eget metus erat. Vivamus sed consequat orci. Aenean commodo lectus sed purus auctor ullamcorper.
</div>
</div>
</div>
</li>
<li>
<div class="date">1999</div>
<div class="circle"></div>
<div class="data">
<div class="subject">Citibank Best Teacher Award (school-wide award, UCLA)</div>
<div class="text row">
<div class="col-md-2">
<img alt="image" class="thumbnail img-responsive" src="img/personal/awards100x100.png" >
</div>
<div class="col-md-10">
Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed egestas dapibus lectus non dignissim. Pellentesque auctor ornare urna, volutpat condimentum quam porttitor at. Vestibulum tincidunt diam in eros aliquam luctus. Donec sagittis a purus a porttitor. Sed non feugiat enim. Donec eget metus erat. Vivamus sed consequat orci. Aenean commodo lectus sed purus auctor ullamcorper.
</div>
</div>
</div>
</li>

</ul>
</div>
</div>
</div>
</div>
</div> -->
</div>

<!-- <div id="research" class="page">
<div class="pageheader">

<div class="headercontent">

<div class="section-container">
<h2 class="title">Research Summary</h2>

<div class="row">
<div class="col-md-8">
<p>Recent trends in deep-submicron very large-scale integration (VLSI) circuit technology have resulted in new requirements for algorithms in integrated circuit layout. Much of my work centers on new formulations that capture performance and density criteria in the physical layout phases of computer-aided design (CAD). Our results include near-optimal approximation algorithms for such computationally difficult problems as minimum-cost Steiner tree routing, low-skew clock networks, cost-radius tradeoffs, bounded-density trees, circuit probe testing, high-performing Elmore-based constructions, layout density control, and improved manufacturability. </p>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
</div>
<div class="col-md-4">
<div class="subtitle text-center">
<h3>Interests</h3>
</div>
<ul class="ul-boxed list-unstyled">
<li>Time, Money and Happiness</li>
<li>The Power of Story</li>
<li>Building Innovative Brands</li>
<li>Cultural Psychology</li>
<li>Emotions, Goals, and Health</li>
<li>computer-aided design</li>
</ul>
</div>
</div>
</div>
</div>
</div>

<div class="pagecontents">
<div class="section color-1">
<div class="section-container">
<div class="title text-center">
<h3>Laboratory Personel</h3>
</div>
<div class="row">
<div class="col-md-8">

<div id="labp-heads-wrap">

<div id="lab-carousel">
<div><img alt="image" src="img/lab/120x120.png" width="120" height="120" class="img-circle lab-img" /></div>
<div><img alt="image" src="img/lab/120x120.png" width="120" height="120" class="img-circle lab-img" /></div>
<div><img alt="image" src="img/lab/120x120.png" width="120" height="120" class="img-circle lab-img" /></div>
<div><img alt="image" src="img/lab/120x120.png" width="120" height="120" class="img-circle lab-img" /></div>
<div><img alt="image" src="img/lab/120x120.png" width="120" height="120" class="img-circle lab-img" /></div>
<div><img alt="image" src="img/lab/120x120.png" width="120" height="120" class="img-circle lab-img" /></div>
</div>
<div>
<a href="#" id="prev"><i class="icon-chevron-sign-left"></i></a>
<a href="#" id="next"><i class="icon-chevron-sign-right"></i></a>
</div>
</div>

<div id="lab-details">
<div>
<h3>David A. Doe</h3>
<h4>Postdoctoral fellow</h4>
<a href="#" class="btn btn-info">+ Follow</a>
</div>
<div>
<h3>James Doe</h3>
<h4>Postdoctoral fellow</h4>
<a href="#" class="btn btn-info">+ Follow</a>
</div>
<div>
<h3>Nadja Sriram</h3>
<h4>Postdoctoral fellow</h4>
<a href="#" class="btn btn-info">+ Follow</a>
</div>
<div>
<h3>Davide Doe</h3>
<h4>Research Assistant</h4>
<a href="#" class="btn btn-info">+ Follow</a>
</div>
<div>
<h3>Pauline Doe</h3>
<h4>Summer Intern</h4>
<a href="#" class="btn btn-info">+ Follow</a>
</div>
<div>
<h3>James Doe</h3>
<h4>Postdoctoral fellow</h4>
<a href="#" class="btn btn-info">+ Follow</a>
</div>
</div>
</div>
<div class="col-md-4">
<h3>Great lab Personel!</h3>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
</div>
</div>
</div>
</div>

<div class="section color-2">
<div class="section-container">
<div class="title text-center">
<h3>Research Projects</h3>
</div>
<div class="row">
<div class="col-md-12">
<ul class="ul-withdetails">
<li>
<div class="row">
<div class="col-sm-6 col-md-3">
<div class="image">
<img alt="image" src="img/lab/400x400.png" class="img-responsive">
<div class="imageoverlay">
<i class="icon icon-search"></i>
</div>

</div>
</div>
<div class="col-sm-6 col-md-9">
<div class="meta">
<h3>Title of Preject</h3>
<p>Very short description of the project.</p>
</div>
</div>
</div>
<div class="details">
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
</div>
</li>
<li>
<div class="row">
<div class="col-sm-6 col-md-3">
<div class="image">
<img alt="image" src="img/lab/400x400.png"  class="img-responsive">
<div class="imageoverlay">
<i class="icon icon-search"></i>
</div>

</div>
</div>
<div class="col-sm-6 col-md-9">
<div class="meta">
<h3>Title of Preject</h3>
<p>Very short description of the project.</p>
</div>
</div>
</div>
<div class="details">
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
</div>
</li>
<li>
<div class="row">
<div class="col-sm-6 col-md-3">
<div class="image">
<img alt="image" src="img/lab/400x400.png"  class="img-responsive">
<div class="imageoverlay">
<i class="icon icon-search"></i>
</div>

</div>
</div>
<div class="col-sm-6 col-md-9">
<div class="meta">
<h3>Title of Preject</h3>
<p>Very short description of the project.</p>
</div>
</div>
</div>
<div class="details">
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
</div>
</li>
<li>
<div class="row">
<div class="col-sm-6 col-md-3">
<div class="image">
<img alt="image" src="img/lab/400x400.png"  class="img-responsive">
<div class="imageoverlay">
<i class="icon icon-search"></i>
</div>

</div>
</div>
<div class="col-sm-6 col-md-9">
<div class="meta">
<h3>Title of Preject</h3>
<p>Very short description of the project.</p>
</div>
</div>
</div>
<div class="details">
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
</div>
</li>
<li>
<div class="row">
<div class="col-sm-6 col-md-3">
<div class="image">
<img alt="image" src="img/lab/400x400.png"  class="img-responsive">
<div class="imageoverlay">
<i class="icon icon-search"></i>
</div>

</div>
</div>
<div class="col-sm-6 col-md-9">
<div class="meta">
<h3>Title of Preject</h3>
<p>Very short description of the project.</p>
</div>
</div>
</div>
<div class="details">
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
</div>
</li>
<li>
<div class="row">
<div class="col-sm-6 col-md-3">
<div class="image">
<img alt="image" src="img/lab/400x400.png"  class="img-responsive">
<div class="imageoverlay">
<i class="icon icon-search"></i>
</div>

</div>
</div>
<div class="col-sm-6 col-md-9">
<div class="meta">
<h3>Title of Preject</h3>
<p>Very short description of the project.</p>
</div>
</div>
</div>
<div class="details">
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
</div>
</li>

</ul>
</div>
</div>
</div>
</div>
</div>
</div> -->

<div id="publications" class="page">
  <div class="page-container">
    <div class="pageheader">
      <div class="headercontent">
        <div class="section-container">

          <h2 class="title">Publications</h2>
          <!-- <div class="row">
          <div class="col-md-12">
          <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
        </div>
      </div> -->

    </div>
  </div>
</div>

<div class="pagecontents">

  <!-- <div class="section color-1" id="filters">
  <div class="section-container">
  <div class="row">

  <div class="col-md-3">
  <h3>Filter by type:</h3>
</div>
<div class="col-md-6">
<select id="cd-dropdown" name="cd-dropdown" class="cd-select">
<option class="filter" value="all" selected>All types</option>
<option class="filter" value="jpaper">Journal Papers</option>
<option class="filter" value="cpaper">Conference Papers</option>
<option class="filter" value="wpaper">Workshop Papers</option>
<option class="filter" value="thesis">Thesis</option>
<option class="filter" value="book">Books</option>
<option class="filter" value="report">Reports</option>
<option class="filter" value="tpaper">Technical Papers</option>
</select>
</div>

<div class="col-md-3" id="sort">
<span>Sort by year:</span>
<div class="btn-group pull-right">

<button type="button" data-sort="data-year" data-order="desc" class="sort btn btn-default"><i class="icon-sort-by-order"></i></button>
<button type="button" data-sort="data-year" data-order="asc" class="sort btn btn-default"><i class="icon-sort-by-order-alt"></i></button>
</div>
</div>
</div>
</div>
</div> -->

<div class="section color-2" id="pub-grid">
  <div class="section-container">

    <div class="row">
      <div class="col-md-12">
        <div class="pitems">

<!-- paper start -->

        <div class="item mix jpaper" data-year="2023">
          <div class="pubmain">
            <div class="pubassets">

              <a href="#" class="pubcollapse">
                <i class="icon-expand-alt"></i>
              </a>
            <a href="https://www.dropbox.com/scl/fi/hfouuq31f9xvewwwq5zt6/2023-SDQ.pdf?rlkey=zrs32p8pnl5yh83n50ff2uq19&dl=§" class="tooltips" title="Download" target="_blank">
              <i class="icon-cloud-download"></i>
            </a>
          </div>

          <h4 class="pubtitle">
            Fabrication-Aware Strip-Decomposable Quadrilateral Meshes
          </h4>
          <div class="pubauthor"> Ioanna Mitropoulou, Amir Vaxman, <strong>Olga Diamanti</strong>, Benjamin Dillenburger </div>
          <div class="pubcite">
            <span class="label label-primary">Journal Paper</span> Computer Aided Design (CAD)
          </div>

        </div>
        <div class="pubdetails">
          <img alt="image" src="img/pubs/2023-SDQ.png" width="200"align="left"  style="padding:10px 30px 0px 0;">
          <h4>Abstract</h4>
          <p>
            Strip-decomposable quadrilateral (SDQ) meshes, i.e., quad meshes that can be decomposed into two transversal strip networks, are vital in numerous fabrication processes; examples include woven structures, surfaces from sheets, custom rebar, or cable-net structures. However, their design is often challenging and includes tedious manual work, and there is a lack of methodologies for editing such meshes while preserving their strip decomposability. We present an interactive methodology to generate and edit SDQ meshes aligned to user-defined directions, while also incorporating desirable properties to the strips for fabrication. Our technique is based on the computation of two coupled transversal tangent direction fields, integrated into two overlapping networks of strips on the surface. As a case study, we consider the fabrication scenario of robotic non-planar 3D printing of free-form surfaces and apply the presented methodology to design and fabricate non-planar print paths.
          </p>
        </div>
      </div>

<!-- paper end -->

<!-- paper start -->

        <div class="item mix cpaper" data-year="2021">
          <div class="pubmain">
            <div class="pubassets">

              <a href="#" class="pubcollapse">
                <i class="icon-expand-alt"></i>
              </a>
            <a href="https://www.dropbox.com/s/op58qwoyo6jusgi/DiscreteConstrainedWillmore.pdf?dl=1" class="tooltips" title="Download" target="_blank">
              <i class="icon-cloud-download"></i>
            </a>
          </div>

          <h4 class="pubtitle">
            Constrained Willmore Surfaces
          </h4>
          <div class="pubauthor"> Yousuf Soliman, Albert Chern, <strong>Olga Diamanti</strong>, Felix Knöppel, Ulrich Pinkall, Peter Schröder</div>
          <div class="pubcite">
            <span class="label label-warning">Conference Paper</span> ACM SIGGRAPH 2021
          </div>

        </div>
        <div class="pubdetails">
          <img alt="image" src="img/pubs/2021-willmore.png" width="200"align="left"  style="padding:10px 30px 0px 0;">
          <h4>Abstract</h4>
          <p>
            Smooth curves and surfaces can be characterized as minimizers of squared curvature bending energies subject to constraints. In the univariate case with an isometry (length) constraint this leads to classic non-linear splines. For surfaces, isometry is too rigid a constraint and instead one asks for minimizers of the Willmore (squared mean curvature) energy subject to a conformality constraint. We present an efficient algorithm for (conformally) constrained Willmore surfaces using triangle meshes of arbitrary topology with or without boundary. Our conformal class constraint is based on the discrete notion of conformal equivalence of triangle meshes. The resulting non-linear constrained optimization problem can be solved efficiently using the competitive gradient descent method together with appropriate Sobolev metrics. The surfaces can be represented either through point positions or differential coordinates. The latter enable the realization of abstract metric surfaces without an initial immersion. A versatile toolkit for extrinsic conformal geometry processing, suitable for the construction and manipulation of smooth surfaces, results through the inclusion of additional point, area, and volume constraints.
          </p>
        </div>
      </div>

<!-- paper end -->

          <div class="item mix cpaper" data-year="2018">
            <div class="pubmain">
              <div class="pubassets">

                <a href="#" class="pubcollapse">
                  <i class="icon-expand-alt"></i>
                </a>
                <!-- <a href="data/2018-templates_vid.mp4" class="tooltips" title="Download-video" target="_blank">
                <i class="icon-cloud-download"></i>
              </a> -->
              <a href="https://www.dropbox.com/s/gsc6v0s961elrf7/2018-templates_supp.pdf?dl=1" class="tooltips" title="Download-supplementary" target="_blank">
                <i class="icon-cloud-download"></i>
              </a>
              <a href="https://www.dropbox.com/s/stkkbo4yxo2z30h/2018-templates.pdf?dl=1" class="tooltips" title="Download" target="_blank">
                <i class="icon-cloud-download"></i>
              </a>
            </div>

            <h4 class="pubtitle">
              Parsing Geometry Using Structure-Aware Shape Templates
            </h4>
            <div class="pubauthor">Vignesh Ganapathi-Subramanian, <strong>Olga Diamanti</strong>, Soeren Pirk, Chengcheng Tang, Matthias Niessner, Leonidas Guibas</div>
            <div class="pubcite">
              <span class="label label-warning">Conference Paper</span> International Conference on 3D Vision (3DV) 2018
            </div>

          </div>
          <div class="pubdetails">
            <img alt="image" src="img/pubs/2018-templates.jpg" width="400"align="left"  style="padding:10px 30px 0px 0;">
            <h4>Abstract</h4>
            <p>
              Real-life man-made objects often exhibit strong and easily-identifiable structure, as a direct result of their design or their intended functionality. Structure typically appears in the form of individual parts and their arrangement. Knowing about object structure can be an important cue for object recognition and scene understanding - a key goal for various AR and robotics applications. However, commodity RGB-D sensors used in these scenarios only produce raw, unorganized point clouds, without structural information about the captured scene. Moreover, the generated data is commonly partial and susceptible to artifacts and noise, which makes inferring the structure of scanned objects challenging. In this paper, we organize large shape collections into parameterized shape templates to capture the underlying structure of the objects. The templates allow us to transfer the structural information onto new objects and incomplete scans. We employ a deep neural network that matches the partial scan with one of the shape templates, then match and fit it to complete and detailed models from the collection. This allows us to faithfully label its parts and to guide the reconstruction of the scanned object. We showcase the effectiveness of our method by comparing it to other state-of-the-art approaches.
            </p>
          </div>
        </div>



        <div class="item mix cpaper" data-year="2018">
          <div class="pubmain">
            <div class="pubassets">

              <a href="#" class="pubcollapse">
                <i class="icon-expand-alt"></i>
              </a>
              <!-- <a href="https://www.igl.ethz.ch/projects/hydrographics/" class="tooltips" title="External link" target="_blank">
              <i class="icon-external-link"></i>
            </a> -->
            <a href="https://www.dropbox.com/s/1akwydgt86eetvd/2018-dirac.pdf?dl=1" class="tooltips" title="Download" target="_blank">
              <i class="icon-cloud-download"></i>
            </a>
          </div>

          <h4 class="pubtitle">
            A unified discrete framework for intrinsic and extrinsic Dirac operators for geometry processing
          </h4>
          <div class="pubauthor">Zi Ye, <strong>Olga Diamanti</strong>,  Chengcheng Tang, Leonidas Guibas, Tim Hoffmann</div>
          <div class="pubcite">
            <span class="label label-warning">Conference Paper</span> EUROGRAPHICS/ACM SIGGRAPH Symposium on Geometry Processing 2018 <font color="#C70039"> <i>  (BEST PAPER AWARD!)</i></font>
          </div>

        </div>
        <div class="pubdetails">
          <img alt="image" src="img/pubs/2018-dirac.jpeg" width="400"align="left"  style="padding:10px 30px 0px 0;">
          <h4>Abstract</h4>
          <p>
            Spectral mesh analysis and processing methods, namely ones that utilize eigenvalues and eigenfunctions of linear operators on meshes, have been applied to numerous geometric processing applications. The operator used predominantly in these methods is the Laplace-Beltrami operator, which has the often-cited property that it is intrinsic, namely invariant to isometric deformation of the underlying geometry, including rigid transformations. Depending on the application, this can be either an advantage or a drawback. Recent work has proposed the alternative of using the Dirac operator on surfaces for spectral processing. The available versions of the Dirac operator only focus on the extrinsic version – however, often a trade-off between the Laplace and Dirac operators is needed. A recent attempt to introduce a range of Dirac-like operators on a spectrum between fully intrinsic and extrinsic produces operators that only loosely relate to Dirac and, importantly, do not relate to conformal surface deformations of the surface, as one would expect from the Dirac operator. In this work, we introduce a unified discretization scheme that describes both an extrinsic and intrinsic Dirac operator on meshes, based on their continuous counterparts on smooth manifolds. In this discretization, both operators are very closely related, and preserve their key properties from the smooth case. We showcase various applications of our operators, with improved numerics over prior work.
          </p>
        </div>
      </div>

      <div class="item mix cpaper" data-year="2018">
        <div class="pubmain">
          <div class="pubassets">

            <a href="#" class="pubcollapse">
              <i class="icon-expand-alt"></i>
            </a>
            <!-- <a href="https://www.igl.ethz.ch/projects/hydrographics/" class="tooltips" title="External link" target="_blank">
            <i class="icon-external-link"></i>
          </a> -->
          <a href="https://www.dropbox.com/s/rlswuxv6waxuslp/2018-alt_diffusion.pdf?dl=1" class="tooltips" title="Download" target="_blank">
            <i class="icon-cloud-download"></i>
          </a>
        </div>

        <h4 class="pubtitle">
          Modular Latent Spaces for Shape Correspondences
        </h4>
        <div class="pubauthor">Vignesh Ganapathi-Subramanian, <strong>Olga Diamanti</strong>, Leonidas Guibas</div>
        <div class="pubcite">
          <span class="label label-warning">Conference Paper</span> EUROGRAPHICS/ACM SIGGRAPH Symposium on Geometry Processing 2018
        </div>

      </div>
      <div class="pubdetails">
        <img alt="image" src="img/pubs/2018-alt_diffusion.png" width="250"align="left"  style="padding:10px 30px 0px 0;">
        <h4>Abstract</h4>
        <p>
          We consider the problem of transporting shape descriptors across shapes in a collection in a modular fashion, in order to establish correspondences between them. A common goal when mapping between multiple shapes is consistency, namely that compositions of maps along a cycle of shapes should be approximately an identity map. Existing attempts to enforce consistency typically require recomputing correspondences whenever a new shape is added to the collection, which can quickly become in- tractable. Instead, we propose an approach that is fully modular, where the bulk of the computation is done on each shape independently. To achieve this, we use intermediate nonlinear embedding spaces, computed individually on every shape; the embedding functions use ideas from diffusion geometry and capture how different descriptors on the same shape inter-relate. We then establish linear mappings between the different embedding spaces, via a shared latent space. The introduction of nonlinear embeddings allows for more nuanced correspondences, while the modularity of the construction allows for paral- lelizable calculation and efficient addition of new shapes. We compare the performance of our framework to standard functional correspondence techniques and showcase the use of this framework to simple interpolation and extrapolation tasks.
        </p>
      </div>
    </div>

    <div class="item mix cpaper" data-year="2018">
      <div class="pubmain">
        <div class="pubassets">

          <a href="#" class="pubcollapse">
            <i class="icon-expand-alt"></i>
          </a>
          <!-- <a href="https://www.igl.ethz.ch/projects/hydrographics/" class="tooltips" title="External link" target="_blank">
          <i class="icon-external-link"></i>
        </a> -->
        <a href="https://www.dropbox.com/s/8gr3wahvqy8xkpo/2018-latent_codes_supp.pdf?dl=1" class="tooltips" title="Download-supplementary" target="_blank">
          <i class="icon-cloud-download"></i>
        </a>
        <a href="https://www.dropbox.com/s/0vjyb5k6vasl0o7/2018-latent_codes.pdf?dl=0" class="tooltips" title="Download" target="_blank">
          <i class="icon-cloud-download"></i>
        </a>
      </div>

      <h4 class="pubtitle">
        Learning Representations and Generative Models for 3D point clouds
      </h4>
      <div class="pubauthor">Panagiotis Achlioptas, <strong>Olga Diamanti</strong>, Ioannis Mitliagkas, Leonidas Guibas</div>
      <div class="pubcite">
        <span class="label label-warning">Conference Paper</span>  International Conference on Machine Learning (ICML) 2018
      </div>

    </div>
    <div class="pubdetails">
      <img alt="image" src="img/pubs/2018-latent_codes.jpg" width="250"align="left"  style="padding:30px 30px 0px 0;">
      <h4>Abstract</h4>
      <p>
        Three-dimensional geometric data offer an excellent domain for studying repre- sentation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep autoencoder (AE) network with excellent reconstruction quality and generalization ability. The learned repre- sentations outperform the state of the art in 3D recognition tasks and enable basic shape editing applications via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation. We also perform a thorough study of different generative models including: GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space our AEs and Gaussian mixture models (GMM). Interestingly, GMMs trained in the latent space of our AEs produce samples of the best fidelity and diversity. To perform our quantitative evaluation of generative models, we propose simple measures of fidelity and diversity based on optimally matching between sets point clouds.
      </p>
    </div>
  </div>


  <div class="item mix wpaper" data-year="2017">
    <div class="pubmain">
      <div class="pubassets">

        <a href="#" class="pubcollapse">
          <i class="icon-expand-alt"></i>
        </a>
        <!-- <a href="https://www.igl.ethz.ch/projects/hydrographics/" class="tooltips" title="External link" target="_blank">
        <i class="icon-external-link"></i>
      </a> -->
      <a href="https://www.dropbox.com/s/kis21e2k0t7urik/2017-latentGANs_ICMLW.pdf?dl=1" class="tooltips" title="Download" target="_blank">
        <i class="icon-cloud-download"></i>
      </a>

    </div>

    <h4 class="pubtitle">
      Latent-space GANs for 3D Point Clouds
    </h4>
    <div class="pubauthor">Panagiotis Achlioptas, <strong>Olga Diamanti</strong>, Ioannis Mitliagkas, Leonidas Guibas</div>
    <div class="pubcite">
      <span class="label label-success">Workshop Paper</span> International Conference on Machine Learning (ICML), Implicit Models Workshop, 2017
    </div>

  </div>
  <div class="pubdetails">
    <img alt="image" src="img/pubs/2017-latentGANs_ICMLW.png" width="200"align="left"  style="padding:10px 30px 0px 0;">
    <h4>Abstract</h4>
    <p>Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep auto-encoder (AE) network for point clouds, which outperforms the state of the art in 3D recognition tasks. We also design GAN architectures to generate novel point-clouds. Most importantly, we show that by training the GAN in the latent space learned by the AE, we greatly boost the GAN’s data-generating capacity, creating significantly more diverse and realistic geometries, with far simpler architectures. The expressive power of our learned embedding, obtained without human supervision, enables basic shape editing applications via simple algebraic manipulations, such as semantic part editing and shape interpolation. </p>
  </div>
</div>



<div class="item mix cpaper" data-year="2017">
  <div class="pubmain">
    <div class="pubassets">

      <a href="#" class="pubcollapse">
        <i class="icon-expand-alt"></i>
      </a>
      <!-- <a href="https://www.igl.ethz.ch/projects/hydrographics/" class="tooltips" title="External link" target="_blank">
      <i class="icon-external-link"></i>
    </a> -->
    <a href="https://www.dropbox.com/s/3zup1u0i2fnym8i/2017-interactions_ICIP.pdf?dl=1" class="tooltips" title="Download" target="_blank">
      <i class="icon-cloud-download"></i>
    </a>
  </div>

  <h4 class="pubtitle">
    Shape- Aware Spatio-Temporal Descriptors for Interaction Classification
  </h4>
  <div class="pubauthor">Soeren Pirk, <strong>Olga Diamanti</strong>,  Boris Thibert, Danfei Xu, Leonidas Guibas</div>
  <div class="pubcite">
    <span class="label label-warning">Conference Paper</span> IEEE International Conference on Image Processing 2017
  </div>

</div>
<div class="pubdetails">
  <img alt="image" src="img/pubs/2017-interactions_ICIP.jpg" width="200"align="left"  style="padding:10px 30px 0px 0;">
  <h4>Abstract</h4>
  <p>Many real-world tasks for autonomous agents benefit from understanding dynamic inter-object interactions. Detecting, analyzing and differentiating between the various ways that an object can be interacted with provides implicit information about its function. This can help train autonomous agents to handle objects and understand unknown scenes. We describe a general mathematical framework to analyze and classify interactions, defined as dynamic motions performed by an active object onto a passive one. We factorize interactions via motion features computed in the spatio-temporal domain, and encoded into a global, object-centric signature. Equipped with a similarity measure to compare such signatures, we showcase classification of interactions with a single object. We also propose a novel acquisition setup combining RGBD sensing with a virtual reality (VR) display, to capture interactions with purely virtual objects.</p>
</div>
</div>


<div class="item mix course" data-year="2016">
  <div class="pubmain">
    <div class="pubassets">

      <a href="#" class="pubcollapse">
        <i class="icon-expand-alt"></i>
      </a>
      <!-- <a href="https://www.igl.ethz.ch/projects/hydrographics/" class="tooltips" title="External link" target="_blank">
      <i class="icon-external-link"></i>
    </a> -->
    <a href="https://www.dropbox.com/s/kpdtxn68ozhooan/2016-directional_fields_STAR.pdf?dl=1" class="tooltips" title="Download" target="_blank">
      <i class="icon-cloud-download"></i>
    </a>

  </div>

  <h4 class="pubtitle">
    Directional Field Synthesis, Design, and Processing
  </h4>
  <div class="pubauthor">Amir Vaxman, Marcel Campen, <strong>Olga Diamanti</strong>,  Daniele Panozzo, David Bommes, Klaus Hildebrandt, Mirela Ben-Chen</div>
  <div class="pubcite">
    <span class="label label-danger">Courses</span> SIGGRAPH Courses 2017, SIGGRAPH Asia Courses 2016, EUROGRAPHICS State of the Art Reports 2016
  </div>

</div>
<div class="pubdetails">
  <img alt="image" src="img/pubs/2016-directional_fields_STAR.png" width="200"align="left"  style="padding:10px 30px 0px 0;">
  <h4>Abstract</h4>
  <p>Direction fields and vector fields play an increasingly important role in computer graphics and geometry processing. The synthesis of directional fields on surfaces, or other spatial domains, is a fundamental step in numerous applications, such as mesh generation, deformation, texture mapping, and many more. The wide range of applications resulted in definitions for many types of directional fields: from vector and tensor fields, over line and cross fields, to frame and vector-set fields.</p>
  <p>Depending on the application at hand, researchers have used various notions of objectives and constraints to synthesize such fields. These notions are defined in terms of fairness, feature alignment, symmetry, or field topology, to mention just a few. To facilitate these objectives, various representations, discretizations, and optimization strategies have been developed. These choices come with varying strengths and weaknesses.</p>
  <p>This report provides a systematic overview of directional field synthesis for graphics applications, the challenges it poses, and the methods developed in recent years to address these challenges. </p>
</div>
</div>


<div class="item mix thesis" data-year="2015">
  <div class="pubmain">
    <div class="pubassets">

      <a href="#" class="pubcollapse">
        <i class="icon-expand-alt"></i>
      </a>
      <!-- <a href="https://www.sciencedirect.com/science/article/pii/S1057740812000290" class="tooltips" title="External link" target="_blank">
      <i class="icon-external-link"></i>
    </a> -->
    <a href="https://www.dropbox.com/s/rs49lujbtqqf13c/phd-thesis.pdf?dl=0" class="tooltips" title="Download" target="_blank">
      <i class="icon-cloud-download"></i>
    </a>
  </div>

  <h4 class="pubtitle">
    Algorithms for User-Guided Surface Mappings</h4>
    <div class="pubauthor"><strong>Olga Diamanti</strong></div>
    <div class="pubcite">
      <span class="label label-info">Thesis</span> Doctoral Thesis, ETH Zurich,  2015</div>

    </div>
    <div class="pubdetails">
      <img alt="image" src="img/pubs/phd_thesis.png" align="left" width="200" style="padding:10px 30px 0px 0;">
      <h4>Abstract</h4>
      <p>Computing mappings between spaces is a very general problem that appears in various forms in geometry processing. They can be used to provide descriptions or representations of shapes, or place shapes in correspondence. Their applications range from surface modeling and analysis to shape matching, morphing, attribute transfer and deformation.</p>

      <p>This thesis addresses two particular mapping problems that are of interest in the field, namely inter-surface maps and parameterizations. We focus on methods that are suitable for user-guided applications - we do not consider automatic methods, that do not leave space for the user to control the result. Existing methods for the particular sub-problems that we are studying often either suffer from performance limitations, or cannot guarantee that the produced results align with the user's intent; we improve upon the state of the art in both those respects.</p>

      <p>The first problem we study in this thesis is that of inter-surface mapping, with given sparse landmark point correspondences. We found that an efficient solution to this otherwise difficult topic emerges if one reformulates the mapping problem as a problem of finding affine combinations of points on the involved shapes. We extend the notion of standard Euclidean weighted averaging to 3D manifold shapes, and introduce a fast approximation that can be used to solve this problem much faster than the state of the art. We showcase applications of this approach in interactive attribute transfer between shapes.</p>

      <p>Next, we move on to the problem of surface parameterization. Here, we study the problem from the application point of view of surface remeshing; a popular way to generate a quadrilateral mesh for a given triangular mesh is to first compute a global parameterization, which is guided by a tangent vector field. This field then determines the directions of the quadrilateral edges on the output mesh. In order to design such a direction field, recent methods to tackle the problem are based on integer optimization problems, which often suffer from slow performance and local minima. We reformulate the problem in a way that the field design problem becomes a linear problem. We also add more flexibility by allowing for non-orthogonal directions.</p>

      <p>Still on the same problem of field-aligned surface parameterizations, we notice that the standard way of producing fields --namely, an optimization only focused on field smoothness-- does not necessarily guarantee that the resulting quadrilateral meshing will be what the user intended in terms of edge directions. This is due to errors introduced in the post-processing of the field, during the later stages of the remeshing pipeline. This renders such fields suboptimal for user-guided meshing applications. We extend our efficient reformulation of the field design problem to generate fields that are guaranteed to not introduce such further errors, and thus make sure that the users obtain the expected results. Additionally, we allow users more flexible control, by supporting assignment of partial constraints for only some of the directions.</p>
    </div>
  </div>

  <div class="item mix cpaper" data-year="2015">
    <div class="pubmain">
      <div class="pubassets">

        <a href="#" class="pubcollapse">
          <i class="icon-expand-alt"></i>
        </a>
        <a href="https://www.igl.ethz.ch/projects/hydrographics/" class="tooltips" title="External link" target="_blank">
          <i class="icon-external-link"></i>
        </a>

      </div>

      <h4 class="pubtitle">
        Texture Mapping Real-World Objects with Hydrographics
      </h4>
      <div class="pubauthor">Daniele Panozzo, <strong>Olga Diamanti</strong>,  Sylvain Paris, Marco Tarini, Evgeni Sorkine, Olga Sorkine-Hornung</div>
      <div class="pubcite">
        <span class="label label-warning">Conference Paper</span> EUROGRAPHICS/ACM SIGGRAPH Symposium on Geometry Processing 2015
      </div>

    </div>
    <div class="pubdetails">
      <img alt="image" src="img/pubs/2015-hydrographics.png" width="200"align="left"  style="padding:10px 30px 0px 0;">
      <h4>Abstract</h4>
      <p>In the digital world, assigning arbitrary colors to an object is a simple operation thanks to texture mapping. However, in the real world, the same basic function of applying colors onto an object is far from trivial. One can specify colors during the fabrication process using a color 3D printer, but this does not apply to already existing objects. Paint and decals can be used during post-fabrication, but they are challenging to apply on complex shapes. In this paper, we develop a method to enable texture mapping of physical objects, that is, we allow one to map an arbitrary color image onto a three-dimensional object. Our approach builds upon hydrographics, a technique to transfer pigments printed on a sheet of polymer onto curved surfaces. We first describe a setup that makes the traditional water transfer printing process more accurate and consistent across prints. We then simulate the transfer process using a specialized parameterization to estimate the mapping between the planar color map and the object surface. We demonstrate that our approach enables the application of detailed color maps onto complex shapes such as 3D models of faces and anatomical casts.</p>
    </div>
  </div>



  <div class="item mix cpaper" data-year="2015">
    <div class="pubmain">
      <div class="pubassets">

        <a href="#" class="pubcollapse">
          <i class="icon-expand-alt"></i>
        </a>
        <a href="https://igl.ethz.ch/projects/integrable/" class="tooltips" title="External link" target="_blank">
          <i class="icon-external-link"></i>
        </a>
      </div>

      <h4 class="pubtitle">Integrable Polyvector Fields </h4>
      <div class="pubauthor"><strong>Olga Diamanti</strong>, Amir Vaxman, Daniele Panozzo, Olga Sorkine-Hornung</div>
      <div class="pubcite"><span class="label label-warning">Conference Paper</span> ACM SIGGRAPH 2015</div>

    </div>
    <div class="pubdetails">
      <img alt="image" src="img/pubs/2015-integrable.png" align="left"  width="200" style="padding:10px 30px 0px 0;">
      <h4>Abstract</h4>
      <p>We present a framework for designing curl-free tangent vector fields on discrete surfaces. Such vector fields are gradients of locally-defined scalar functions, and this property is beneficial for creating surface parameterizations, since the gradients of the parameterization coordinate functions are then exactly aligned with the designed fields.

        We introduce a novel definition for discrete curl between unordered sets of vectors (PolyVectors), and devise a curl-eliminating continuous optimization that is independent of the matchings between them. Our algorithm naturally places the singularities required to satisfy the user-provided alignment constraints, and our fields are the gradients of an inversion-free parameterization by design.</p>
      </div>
    </div>



    <div class="item mix jpaper" data-year="2015">
      <div class="pubmain">
        <div class="pubassets">

          <a href="#" class="pubcollapse">
            <i class="icon-expand-alt"></i>
          </a>
          <a href="https://igl.ethz.ch/projects/texsynth/" class="tooltips" title="External link" target="_blank">
            <i class="icon-external-link"></i>
          </a>

        </div>

        <h4 class="pubtitle">
          Synthesis of Complex Image Appearance from Limited Exemplars
        </h4>
        <div class="pubauthor"><strong>Olga Diamanti</strong>,  Connelly Barnes, Sylvain Paris, Eli Shechtman, Olga Sorkine-Hornung</div>
        <div class="pubcite">
          <span class="label label-primary">Journal Paper</span> ACM Transactions on Graphics, Volume 34 Issue 2, February 2015, Article No. 22
        </div>

      </div>
      <div class="pubdetails">
        <img alt="image" src="img/pubs/2015-texsynth.png" width="155"align="left"  style="padding:10px 30px 0px 0;">
        <h4>Abstract</h4>
        <p>Editing materials in photos opens up numerous opportunities like turning an unappealing dirt ground into luscious grass and creating a comfortable wool sweater in place of a cheap t-shirt. However, such edits are challenging. Approaches such as 3D rendering and BTF rendering can represent virtually everything, but they are also data intensive and computationally expensive, which makes user interaction difficult. Leaner methods such as texture synthesis are more easily controllable by artists, but also more limited in the range of materials that they handle, for example, grass and wool are typically problematic because of their non-Lambertian reflectance and numerous self-occlusions. We propose a new approach for editing of complex materials in photographs. We extend the texture-by-numbers approach with ideas from texture interpolation. The inputs to our method are coarse user annotation maps that specify the desired output, such as the local scale of the material and the illumination direction. Our algorithm then synthesizes the output from a discrete set of annotated exemplars. A key component of our method is that it can cope with missing data, interpolating information from the available exemplars when needed. This enables production of satisfying results involving materials with complex appearance variations such as foliage, carpet, and fabric from only one or a couple of exemplar photographs.</p>
      </div>
    </div>


    <div class="item mix cpaper" data-year="2015">
      <div class="pubmain">
        <div class="pubassets">

          <a href="#" class="pubcollapse">
            <i class="icon-expand-alt"></i>
          </a>
          <a href="https://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=7045961" class="tooltips" title="External link" target="_blank">
            <i class="icon-external-link"></i>
          </a>
          <!-- <a href="https://faculty-gsb.stanford.edu/aaker/pages/documents/CultivatingAdmirationinBrands_JCP2012.pdf" class="tooltips" title="Download" target="_blank">
          <i class="icon-cloud-download"></i>
        </a> -->

      </div>

      <h4 class="pubtitle">
        Extending the Performance of Human Classifiers Using a Viewpoint Specific Approach</h4>
        <div class="pubauthor">Endri Dibra, Jerome Maye, <strong>Olga Diamanti</strong>, Roland Siegwart, Paul Beardsley</div>
        <div class="pubcite"><span class="label label-warning">Conference Paper</span> IEEE Winter Conference on Applications of Computer Vision (WACV), 2015</div>

      </div>
      <div class="pubdetails">
        <img alt="image" src="img/pubs/2015-viewpoint_specific.png" align="left" width="145" style="padding:10px 30px 0px 0;">
        <h4>Abstract</h4>
        <p>This paper describes human classifiers that are 'viewpoint specific', meaning specific to subjects being observed by a particular camera in a particular scene. The advantages of the approach are (a) improved human detection in the presence of perspective foreshortening from an elevated camera, (b) ability to handle partial occlusion of subjects e.g. partial occlusion by furniture in an indoor scene, and (c) ability to detect subjects when partially truncated at the top, bottom or sides of the image. Elevated camera views will typically generate truncated views for subjects at the image edges but our viewpoint specific method handles such cases and thereby extends overall detection coverage. The approach is - (a) define a tiling on the ground plane of the 3D scene, (b) generate training images per tile using virtual humans, (c) train a classifier per tile (d) run the classifiers on the real scene. The approach would be prohibitive if each new deployment required real training images, but it is feasible because training is done with a virtual humans inserted into a scene model. The classifier is a linear SVM and HOGs. Experimental results provide a comparative analysis with existing algorithms to demonstrate the advantages described above.</p>
      </div>
    </div>




    <div class="item mix cpaper" data-year="2014">
      <div class="pubmain">
        <div class="pubassets">

          <a href="#" class="pubcollapse">
            <i class="icon-expand-alt"></i>
          </a>
          <a href="https://cgl.ethz.ch/publications/papers/paperCha14b.php#" class="tooltips" title="External link" target="_blank">
            <i class="icon-external-link"></i>
          </a>
          <!-- <a href="https://faculty-gsb.stanford.edu/aaker/pages/documents/CultivatingAdmirationinBrands_JCP2012.pdf" class="tooltips" title="Download" target="_blank">
          <i class="icon-cloud-download"></i>
        </a> -->

      </div>

      <h4 class="pubtitle">Perceptual Evaluation of Cardboarding in 3D Content Visualization</h4>
      <div class="pubauthor">Alexandre Chapiro, <strong>Olga Diamanti</strong>, Steven Poulakos, Carol O'Sullivan, Aljoscha Smolic, Markus Gross</div>
      <div class="pubcite"><span class="label label-warning">Conference Paper</span> ACM Symposium on Applied Perception (SAP), 2014</div>

    </div>
    <div class="pubdetails">
      <img alt="image" src="img/pubs/PORC_teaser.jpg" align="left" width="145" style="padding:10px 30px 0px 0;">
      <h4>Abstract</h4>
      <p>A pervasive artifact that occurs when visualizing 3D content is the so-called "cardboarding" effect, where objects appear flat due to depth compression, with relatively little research conducted to perceptually quantify its effects. Our aim is to shed light on the subjective preferences and practical perceptual limits of stereo vision with respect to cardboarding. We present three experiments that explore the consequences of displaying simple scenes with reduced depths using both subjective ratings and adjustments and objective sensitivity metrics. Our results suggest that compressing depth to 80% or above is likely to be acceptable, whereas sensitivity to the cardboarding artifact below 30% is very high. These values could be used in practice as guidelines for commonplace depth mapping operations in 3D production pipelines.</p>
    </div>
  </div>


  <div class="item mix cpaper" data-year="2014">
    <div class="pubmain">
      <div class="pubassets">

        <a href="#" class="pubcollapse">
          <i class="icon-expand-alt"></i>
        </a>
        <a href="https://www.igl.ethz.ch/projects/complex-roots/" class="tooltips" title="External link" target="_blank">
          <i class="icon-external-link"></i>
        </a>

      </div>

      <h4 class="pubtitle">
        Designing N-PolyVector Fields with Complex Polynomials
      </h4>
      <div class="pubauthor"><strong>Olga Diamanti</strong>, Amir Vaxman, Daniele Panozzo, Olga Sorkine-Hornung</div>
      <div class="pubcite">
        <span class="label label-warning">Conference Paper</span> EUROGRAPHICS/ACM SIGGRAPH Symposium on Geometry Processing 2014 <font color="#C70039"> <i>  (BEST PAPER AWARD!)</i></font>
      </div>

    </div>
    <div class="pubdetails">
      <img alt="image" src="img/pubs/2014-complex-roots.png" width="155"align="left"  style="padding:10px 30px 0px 0;">
      <h4>Abstract</h4>
      <p>We introduce N-PolyVector fields, a generalization of N-RoSy fields for which the vectors are neither necessarily orthogonal nor rotationally symmetric. We formally define a novel representation for N-PolyVectors as the root sets of complex polynomials and analyze their topological and geometric properties. A smooth N-PolyVector field can be efficiently generated by solving a sparse linear system without integer variables. We exploit the flexibility of N-PolyVector fields to design conjugate vector fields, offering an intuitive tool to generate planar quadrilateral meshes.</p>
    </div>
  </div>

  <div class="item mix cpaper" data-year="2013">
    <div class="pubmain">
      <div class="pubassets">

        <a href="#" class="pubcollapse">
          <i class="icon-expand-alt"></i>
        </a>
        <a href="https://igl.ethz.ch/projects/wa/" class="tooltips" title="External link" target="_blank">
          <i class="icon-external-link"></i>
        </a>
        <!-- <a href="https://faculty-gsb.stanford.edu/aaker/pages/documents/CultivatingAdmirationinBrands_JCP2012.pdf" class="tooltips" title="Download" target="_blank">
        <i class="icon-cloud-download"></i>
      </a> -->

    </div>

    <h4 class="pubtitle">Weighted Averages on Surfaces</h4>
    <div class="pubauthor">Daniele Panozzo, Ilya Baran, <strong>Olga Diamanti</strong>, Olga Sorkine-Hornung</div>
    <div class="pubcite"><span class="label label-warning">Conference Paper</span> ACM SIGGRAPH 2013</div>

  </div>
  <div class="pubdetails">
    <img alt="image" src="img/pubs/wa.png" align="left"  width="155" style="padding:10px 30px 0px 0;">
    <h4>Abstract</h4>
    <p>We consider the problem of generalizing affine combinations in Euclidean spaces to triangle meshes: computing weighted averages of points on surfaces. We address both the forward problem, namely computing an average of given anchor points on the mesh with given weights, and the inverse problem, which is computing the weights given anchor points and a target point. Solving the forward problem on a mesh enables applications such as splines on surfaces, Laplacian smoothing and remeshing. Combining the forward and inverse problems allows us to define a correspondence mapping between two different meshes based on provided corresponding point pairs, enabling texture transfer, compatible remeshing, morphing and more. Our algorithm solves a single instance of a forward or an inverse problem in a few microseconds. We demonstrate that anchor points in the above applications can be added/removed and moved around on the meshes at interactive framerates, giving the user an immediate result as feedback.</p>
  </div>
</div>

<div class="item mix thesis" data-year="2010">
  <div class="pubmain">
    <div class="pubassets">

      <a href="#" class="pubcollapse">
        <i class="icon-expand-alt"></i>
      </a>
      <!-- <a href="https://www.sciencedirect.com/science/article/pii/S1057740812000290" class="tooltips" title="External link" target="_blank">
      <i class="icon-external-link"></i>
    </a> -->
    <a href="https://www.dropbox.com/s/mkubkae1475jqiz/ethz_thesis.pdf?dl=1" class="tooltips" title="Download" target="_blank">
      <i class="icon-cloud-download"></i>
    </a>
  </div>

  <h4 class="pubtitle">
    Motion Capture in Uncontrolled Environments</h4>
    <div class="pubauthor"><strong>Olga Diamanti</strong></div>
    <div class="pubcite">
      <span class="label label-info">Thesis</span> Master's Thesis, ETH Zurich,  2010</div>

    </div>
    <div class="pubdetails">
      <img alt="image" src="img/pubs/ethz_thesis.png" align="left" width="155" style="padding:10px 30px 0px 0;">
      <h4>Abstract</h4>
      <p>The  goal of a markerless motion algorithm is to recover the pose of a person from a set of images or videos. This is typically addressed in two ways: global optimization, used primarily when pose detection is the main interest, and/or local optimization, when the focus is on pose tracking. While the latter can provide very accurate results in relatively little time, it suffers from sensitivity to local minima. On the contrary, the former approach ensures a correct estimation of the pose, even without any prior pose information, at the cost of much higher computational complexity.</p>

      <p>This thesis addresses the pose detection problem in both these ways by enhancing an already existing tracking approach so as to obtain a robust motion capture algorithm. This allows us to track people also in not controlled environments, such as in the case of outdoor scenarios. Additionally, we incorporate appearance modeling (by means of a texture map) with the aim to improve the tracking results.</p>
    </div>
  </div>



  <div class="item mix cpaper" data-year="2008">
    <div class="pubmain">
      <div class="pubassets">

        <a href="#" class="pubcollapse">
          <i class="icon-expand-alt"></i>
        </a>
        <a href="https://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=4711950" class="tooltips" title="External link" target="_blank">
          <i class="icon-external-link"></i>
        </a>

      </div>

      <h4 class="pubtitle">
        Geodesic Active Regions For Segmentation and Tracking of Human Gestures in Sign Language Videos</h4>
        <div class="pubauthor"><strong>Olga Diamanti</strong>,  Petros Maragos</div>
        <div class="pubcite">
          <span class="label label-warning">Conference Paper</span> IEEE International Conference on Image Processing (ICIP), 2008.</div>

        </div>
        <div class="pubdetails">
          <img alt="image" src="img/pubs/GAR.png" align="left"  width="185" style="padding:10px 30px 0px 0;">
          <h4>Abstract</h4>
          <p>Reliable segmentation and motion tracking algorithms are required to achieve gesture detection and tracking for human-machine interaction. In this paper we present an efficient method for detecting and tracking moving hands in sign language video frames. We make use of the geodesic active region framework in conjunction with new color and motion forces; color information is provided by a skin color model, while motion information is derived from the optical flow field. Extensive experimentation indicates that the proposed algorithm behaves sufficiently well for gesture detection and tracking.</p>
        </div>
      </div>

      <div class="item mix cpaper" data-year="2009">
        <div class="pubmain">
          <div class="pubassets">

            <a href="#" class="pubcollapse">
              <i class="icon-expand-alt"></i>
            </a>
            <a href="https://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=5326235" class="tooltips" title="External link" target="_blank">
              <i class="icon-external-link"></i>
            </a>
            <!-- <a href="https://faculty-gsb.stanford.edu/aaker/pages/documents/CultivatingAdmirationinBrands_JCP2012.pdf" class="tooltips" title="Download" target="_blank">
            <i class="icon-cloud-download"></i>
          </a> -->

        </div>

        <h4 class="pubtitle">Gestural teleoperation of a mobile robot based on visual recognition of sign language static handshapes</h4>
        <div class="pubauthor">C. Tzafestas, N.Mitsou, N. Georgakakos, <strong>O. Diamanti</strong>, P. Maragos, S.-E. Fotinea and E. Efthimiou</div>
        <div class="pubcite"><span class="label label-warning">Conference Paper</span> IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), 2009</div>

      </div>
      <div class="pubdetails">
        <img alt="image" src="img/pubs/teleop.png" align="left"  width="155" style="padding:10px 30px 0px 0;">
        <h4>Abstract</h4>
        <p>This paper presents results achieved in the frames of a national research project (titled <q>DIANOEMA</q>), where visual analysis and sign recognition techniques have been explored on Greek Sign Language (GSL) data. Besides GSL modelling, the aim was to develop a pilot application for teleoperating a mobile robot using natural hand signs. A small vocabulary of hand signs has been designed to enable desktopbased teleoperation at a high-level of supervisory telerobotic control. Real-time visual recognition of the hand images is performed by training a multi-layer perceptron (MLP) neural network. Various shape descriptors of the segmented hand posture images have been explored as inputs to the MLP network. These include Fourier shape descriptors on the contour of the segmented hand sign images, moments, compactness, eccentricity, and histogram of the curvature. We have examined which of these shape descriptors are best suited for real-time recognition of hand signs, in relation to the number and choice of hand postures, in order to achieve maximum recognition performance. The hand-sign recognizer has been integrated in a graphical user interface, and has been implemented with success on a pilot application for real-time desktop-based gestural teleoperation of a mobile robot vehicle.</p>
      </div>
    </div>
    <div class="item mix wpaper" data-year="2009">
      <div class="pubmain">
        <div class="pubassets">

          <a href="#" class="pubcollapse">
            <i class="icon-expand-alt"></i>
          </a>
          <!-- <a href="https://www.sciencedirect.com/science/article/pii/S1057740812000290" class="tooltips" title="External link" target="_blank">
          <i class="icon-external-link"></i>
        </a> -->
        <a href="http://www.image.ece.ntua.gr/papers/582.pdf" class="tooltips" title="Download" target="_blank">
          <i class="icon-cloud-download"></i>
        </a>

      </div>

      <h4 class="pubtitle">DIANOEMA: Visual analysis and sign recognition for GSL modelling and robot teleoperation</h4>
      <div class="pubauthor">S.-E. Fotinea, E. Efthimiou, G. Caridakis, <strong>O. Diamanti</strong>, N. Mitsou, K. Karpouzis, C. Tzafestas and P. Maragos</div>
      <div class="pubcite"><span class="label label-success">Workshop Paper</span> 8th International Gesture Workshop (GW), 2009.</div>

    </div>
    <div class="pubdetails">
      <img alt="image" src="img/pubs/DIANOEMA.png" align="left"  width="185" style="padding:10px 30px 0px 0;">
      <h4>Abstract</h4>
      <p>This paper presents the scientific framework and achieved results of
        the DIANOEMA project, in the framework of which visual analysis and sign
        recognition techniques have been explored on Greek Sign Language (GSL) data
        aiming at GSL modelling and a pilot application for robot teleoperation. The
        project’s accomplishments comprise the Greek Sign Language Corpus (GSLC)
        creation and annotation, video analysis algorithms for automatic visual
        detection and gesture tracking, a probabilistic recognition scheme for
        Automatic Sign Language Recognition from multiple cues, and the pilot
        application on teleoperation of a Mobile Robot Vehicle. </p>
      </div>
    </div>


    <div class="item mix cpaper" data-year="2008">
      <div class="pubmain">
        <div class="pubassets">

          <a href="#" class="pubcollapse">
            <i class="icon-expand-alt"></i>
          </a>
          <a href="https://dl.acm.org/citation.cfm?id=1389687" class="tooltips" title="External link" target="_blank">
            <i class="icon-external-link"></i>
          </a>

        </div>

        <h4 class="pubtitle">
          Automatic Sign Language Recognition: vision based feature extraction and probabilistic recognition scheme from multiple cues</h4>
          <div class="pubauthor">G. Caridakis, <strong>O. Diamanti</strong>, K. Karpouzis and P. Maragos
          </div>
          <div class="pubcite">
            <span class="label label-warning">Conference Paper</span> 1st ACM International Conference on Pervasive Technologies Related to Assistive Environments, Affect-aware Human-Computer and Human-Robot Interaction (PETRAE),  2008.</div>

          </div>
          <div class="pubdetails">
            <img alt="image" src="img/pubs/ASL.png" align="left" width="185" style="padding:10px 30px 0px 0;">
            <h4>Abstract</h4>
            <p>This work focuses on two of the research problems comprising automatic sign language recognition, namely robust computer vision techniques for consistent hand detection and tracking, while preserving the hand shape contour which is useful for extraction of features related to the handshape and a novel classification scheme incorporating Self-organizing maps, Markov chains and Hidden Markov Models. Geodesic Active Contours enhanced with skin color and motion information are employed for the hand detection and the extraction of the hand silhouette, while features extracted describe hand trajectory, region and shape. Extracted features are used as input to separate classifiers, forming a robust and adaptive architecture whose main contribution is the optimal utilization of the neighboring characteristic of the SOM during the decoding stage of the Markov chain, representing the sign class.</p>
          </div>
        </div>


        <div class="item mix thesis" data-year="2007">
          <div class="pubmain">
            <div class="pubassets">

              <a href="#" class="pubcollapse">
                <i class="icon-expand-alt"></i>
              </a>
              <!-- <a href="https://www.sciencedirect.com/science/article/pii/S1057740812000290" class="tooltips" title="External link" target="_blank">
              <i class="icon-external-link"></i>
            </a> -->
            <a href="https://www.dropbox.com/s/97hrkix0m10ov3s/ntua_thesis.pdf?dl=1" class="tooltips" title="Download" target="_blank">
              <i class="icon-cloud-download"></i>
            </a>
          </div>

          <h4 class="pubtitle">
            Visual Analysis of Sign Language Videos : Image Segmentation,
            Motion Tracking and Feature Extraction</h4>
            <div class="pubauthor"><strong>Olga Diamanti</strong></div>
            <div class="pubcite">
              <span class="label label-info">Thesis</span> Diploma Thesis, National Technical University of Athens,  2007</div>

            </div>
            <div class="pubdetails">
              <img alt="image" src="img/pubs/ntua_thesis.png" align="left" width="155" style="padding:10px 30px 0px 0;">
              <h4>Abstract</h4>
              <p>The goal of this thesis is to test, extend and develop methods for the implementation of a sign language recognition (SLR) system based on the visual analysis of sign language videos. This application is part of the more general research area referred to as "human-machine interaction", which is strongly related to the science and technology of Computer Vision. More specifically, this thesis focuses on all the stages that are required prior to the recognition phase of a SLE system, namely the image segmentation, motion tracking and deature extraction stages. Special effort was made to cope with one of the most commonly met problems in SLR, which is the vagueness introduces in cases of hand-hand or hand-face occlusions. In each stage, a variety of methods and techniques is explored, which were retrieved following an extensive search of the state-of-the-art literature. The overall system is to be used (in combination with the necessary recognition stage) in the construction of a real practical SLR system for the recognition of a set of Greek Sign Language signs, as part of the research project "DIANOEMA". </p>
            </div>
          </div>


        </div>
      </div>
    </div>

  </div>
</div>

</div>
</div>
</div>


<div id="teaching" class="page">
  <div class="pageheader">
    <div class="headercontent">
      <div class="section-container">

        <h2 class="title">Teaching</h2>

        <!-- <div class="row">
        <div class="col-md-12">
        <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
      </div>
    </div> -->
  </div>
</div>
</div>
<div class="pagecontents">
  <div class="section color-1">
    <div class="section-container">
      <div class="row">
        <div class="title text-center">
          <h3>Current Courses</h3>
        </div>
        <ul class="ul-dates">
          <li>
            <div class="dates">
              <span>Winter</span>
              <!-- <span>2021&ndash;now</span> -->
              <span> &nbsp;</span>
            </div>
            <div class="content">
              <img alt="image" src="img/teaching/edg2021.png" align="right" height="75" style="margin:-10px 0px 0px 0px;">
              <h4><a href="https://online.tugraz.at/tug_online/wbLv.wbShowLVDetail?pStpSpNr=237130">Elementary Differential Geometry</a></h4>
              <p>Instructor, TU Graz.</p>
            </div>
          </li>
          <li>
            <div class="dates">
              <span>Summer</span>
              <!-- <span>2021 &ndash;now</span> -->
              <span> &nbsp;</span>
            </div>
            <div class="content">
              <img alt="image" src="img/teaching/fgp2020.png" align="right" height="75" style="margin:-10px 0px 0px 0px;">
              <h4><a href="https://online.tugraz.at/tug_online/wbLv.wbShowLVDetail?pStpSpNr=237130">Foundations of Geometry Processing</a></h4>
              <p>Co &ndash;Instructor, TU Graz.</p>
            </div>
          </li>
          <li>
            <div class="dates">
              <span>Summer</span>
              <!-- <span>2021 &ndash;now</span> -->
              <span> &nbsp;</span>
            </div>
            <div class="content">
              <img alt="image" src="img/teaching/scicomm2021.png" align="right" height="75" style="margin:-10px 0px 0px 0px;">
              <h4><a href="https://online.tugraz.at/tug_online/wbLv.wbShowLVDetail?pStpSpNr=205331">Scientific Communication</a></h4>
              <p>Co &ndash;Instructor, TU Graz.</p>
            </div>
          </li>
          <li>
            <div class="dates">
              <span>Winter</span>
              <!-- <span>2020 &ndash;now</span> -->
              <span> &nbsp;</span>
            </div>
            <div class="content">
              <img alt="image" src="img/teaching/gfcs2020.jpg" align="right" height="75" style="margin:-10px 0px 0px 0px;">
              <h4><a href="https://online.tugraz.at/tug_online/wbLv.wbShowLVDetail?pStpSpNr=237130">Geometry for Computer Scientists</a></h4>
              <p>Instructor, TU Graz.</p>
            </div>
          </li>
          <li>
            <div class="dates">
              <span>Winter</span>
              <!-- <span>2020 &ndash;now</span> -->
              <span> &nbsp;</span>
            </div>
            <div class="content">
              <img alt="image" src="img/teaching/aggm2020.jpg" align="right" height="75" style="margin:-10px 0px 0px 0px;">
              <h4><a href="https://online.tugraz.at/tug_online/wbLv.wbShowLVDetail?pStpSpNr=239986">Applied Geometry</a></h4>
              <p>Instructor, TU Graz.</p>
            </div>
          </li>
        </ul>
      </div>
    </div>
  </div>
  <div class="section color-2">
    <div class="section-container">
      <div class="row">
        <div class="title text-center">
          <h3>Past Courses</h3>
        </div>
        <ul class="ul-dates-gray">
          <li>
            <div class="dates">
              <span>Winter</span>
              <span>2019</span>
            </div>
            <div class="content">
              <img alt="image" src="img/teaching/gpa2019.png" align="right" height="75" style="margin:-10px 0px 0px 0px;">
              <h4><a href="http://dgd.service.tu-berlin.de/wordpress/geometryprocessingandapplicationsws19/">Geometry Processing and Applications</a></h4>
              <p>Co-Instructor, TU Berlin.</p>
            </div>
          </li>
          <li>
            <div class="dates">
              <span>Spring</span>
              <span>2017</span>
            </div>
            <div class="content">
              <img alt="image" src="img/teaching/ml3d2017.png" align="right" height="75" style="margin:-10px 0px 0px 0px;">
              <h4><a href="https://graphics.stanford.edu/courses/cs468-17-spring/">CS468 - Machine Learning for 3D Data</a></h4>
              <p>Selected Lectures and Teaching Assistance, Stanford University.</p>
            </div>
          </li>
          <li>
            <div class="dates">
              <span>Winter</span>
              <span>2016</span>
            </div>
            <div class="content">
              <img alt="image" src="img/teaching/cggmp2017.png" align="right" height="75" style="margin:-10px 0px 0px 0px;">
              <h4><a href="https://graphics.stanford.edu/courses/cs348a-17-winter/">CS348a - Computer Graphics: Geometric Modeling/Processing</a></h4>
              <p>Selected Lectures, Stanford University.</p>
            </div>
          </li>
          <li>
            <div class="dates">
              <span>Spring</span>
              <span>2015</span>
            </div>
            <div class="content">
              <img alt="image" src="img/teaching/sm2015.png" align="right" height="75" style="margin:-10px 0px 0px 0px;">
              <h4><a href="https://www.igl.ethz.ch/teaching/shape-modeling/sm2015/">Shape Modeling and Geometry Processing</a></h4>
              <p>Teaching Assistant, ETH Zurich.</p>
            </div>
          </li>
          <li>
            <div class="dates">
              <span>Autumn</span>
              <span>2014</span>
            </div>
            <div class="content">
              <img alt="image" src="img/teaching/infk2014.jpg" align="right" height="75" style="margin:-10px 0px 0px 0px;">
              <h4><a href="https://www.crypto.ethz.ch/teaching/lectures/InfBau14/">Informatik 1 DBAUG</a></h4>
              <p>Teaching Assistant, ETH Zurich. </p>
            </div>
          </li>
          <li>
            <div class="dates">
              <span>Spring</span>
              <span>2014</span>
            </div>
            <div class="content">
              <img alt="image" src="img/teaching/sm2014.png" align="right" height="75" style="margin:-10px 0px 0px 0px;">
              <h4><a href="https://www.igl.ethz.ch/teaching/shape-modeling/sm2014/">Shape Modeling and Geometry Processing</a></h4>
              <p>Teaching Assistant, ETH Zurich</p>
            </div>
          </li>
          <li>
            <div class="dates">
              <span>Spring</span>
              <span>2013</span>
            </div>
            <div class="content">
              <img alt="image" src="img/teaching/sm2013.png" align="right" height="75" style="margin:-10px 0px 0px 0px;">
              <h4><a href="https://www.igl.ethz.ch/teaching/shape-modeling/sm2013/">Shape Modeling and Geometry Processing</a></h4>
              <p>Teaching Assistant, ETH Zurich</p>
            </div>
          </li>
          <li>
            <div class="dates">
              <span>Spring</span>
              <span>2012</span>
            </div>
            <div class="content">
              <img alt="image" src="img/teaching/sm2012.png" align="right" height="75" style="margin:-10px 0px 0px 0px;">
              <h4><a href="https://www.igl.ethz.ch/teaching/shape-modeling/sm2012/">Shape Modeling and Geometry Processing</a></h4>
              <p>Teaching Assistant, ETH Zurich</p>
            </div>
          </li>
        </ul>
      </div>
    </div>
  </div>
</div>
</div>


<!-- <div id="gallery" class="page">
<div class="pagecontents">

<div class="section color-3" id="gallery-header">
<div class="section-container">
<div class="row">
<div class="col-md-3">
<h2>Gallery</h2>
</div>
<div class="col-md-9">
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
</div>
</div>
</div>
</div>

<div class="section color-3" id="gallery-large">
<div class="section-container">

<ul id="grid" class="grid">
<li>
<div>
<img alt="image" src="img/gallery/450x600.png">
<a href="img/gallery/450x600.png" class="popup-with-move-anim">
<div class="over">
<div class="comein">
<i class="icon-search"></i>
<div class="comein-bg"></div>
</div>
</div>
</a>
</div>
</li>
<li>
<div>
<img alt="image" src="img/gallery/600x600.png">
<a href="img/gallery/600x500.png" class="popup-with-move-anim">
<div class="over">
<div class="comein">
<h3>Image Title</h3>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
<div class="comein-bg"></div>
</div>
</div>
</a>
</div>
</li>
<li>
<div>
<img alt="image" src="img/gallery/900x600.png">
<a href="img/gallery/900x600.png" class="popup-with-move-anim">
<div class="over">
<div class="comein">
<i class="icon-search"></i>
<div class="comein-bg"></div>
</div>
</div>
</a>
</div>
</li>
<li>
<div>
<img alt="image" src="img/gallery/400x300.png">
<a href="img/gallery/400x300.png" class="popup-with-move-anim">
<div class="over">
<div class="comein">
<h3>Image Title</h3>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
<div class="comein-bg"></div>
</div>
</div>
</a>
</div>
</li>
<li>
<div>
<img alt="image" src="img/gallery/400x300.png">
<a href="img/gallery/400x300.png" class="popup-with-move-anim">
<div class="over">
<div class="comein">
<i class="icon-search"></i>
<div class="comein-bg"></div>
</div>
</div>
</a>
</div>
</li>
<li>
<div>
<img alt="image" src="img/gallery/800x600.png">
<a href="img/gallery/800x600.png" class="popup-with-move-anim">
<div class="over">
<div class="comein">
<h3>Image Title</h3>
<p>Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
<div class="comein-bg"></div>
</div>
</div>
</a>
</div>
</li>


</ul>

</div>
</div>
</div>

</div>
-->

<div id="contact" class="page stellar">
  <div class="pageheader">
    <div class="headercontent">
      <div class="section-container">

        <h2 class="title">Contact Me</h2>

        <div class="row">
          <!-- <div class="col-md-8">
          <p>I would be happy to talk to you if you need my assistance in your research or whether you need bussiness administration support for your company. Though I have limited time for students but I Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>
        </div> -->
        <div class="col-md-10">
          <ul class="list-unstyled">
            <li>
              <strong><i class="icon-building"></i>&nbsp;&nbsp;</strong>
              <span>Kopernikusgasse 24/IV, Raum NT04012, TU Graz, 8010 Graz, Austria</span>
            </li>
            <li>
              <strong><i class="icon-phone"></i>&nbsp;&nbsp;</strong>
              <span>+43 (316) 873 - 8442</span>
            </li>
            <li>
              <strong><i class="icon-envelope"></i>&nbsp;&nbsp;</strong>
              <span>olga.diamanti_at_tugraz.at</span>
            </li>
            <!-- <li>
            <strong><i class="icon-envelope"></i>&nbsp;&nbsp;</strong>
            <span>olga.diam_at_gmail.com</span>
          </li> -->
          <li>
            <strong><i class="icon-skype"></i>&nbsp;&nbsp;</strong>
            <span>olga.diam</span>
          </li>
          <!-- <li>
          <strong><i class="icon-twitter"></i>&nbsp;&nbsp;</strong>
          <span>#jenniferDoe</span>
        </li> -->
        <!-- <li>
        <strong><i class="icon-linkedin-sign"></i>&nbsp;&nbsp;</strong>
        <span><a href="#">us.linkedin.com/in/jdoe</a></span>
      </li> -->
    </ul>

  </div>
</div>
</div>
</div>
</div>
<!-- <div class="pagecontents">
<div class="section contact-office" data-stellar-background-ratio="0.1">
<div class="section-container">
<div class="row">
<div class="col-md-8">
<h2 class="title">At My Office</h2>
<p>You can find me at my office located at Stanford University Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
<p>I am at my office every day from 7:00 until 10:00 am, but you may consider a call to fix an appointment.</p>
</div>
<div class="col-md-4 text-center hidden-xs hidden-sm">
<i class="icon-coffee icon-huge"></i>
</div>

</div>
</div>
</div>
<div class="section color-1">
<div class="section-container">
<div class="row">
<div class="col-md-4 text-center hidden-xs hidden-sm">
<i class="icon-stethoscope icon-huge"></i>
</div>
<div class="col-md-8">
<h2 class="title">At My Work</h2>
<p>You can find me at my Work located at Stanford University Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
<p>I am at my office every day from 7:00 until 10:00 am, but you may consider a call to fix an appointment.</p>
</div>
</div>
</div>
</div>
<div class="section contact-lab" data-stellar-background-ratio="0.1">
<div class="section-container">
<div class="row">

<div class="col-md-8">
<h2 class="title">At My Lab</h2>
<p>You can find me at my office located at Stanford University Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.</p>
<p>I am at my office every day from 7:00 until 10:00 am, but you may consider a call to fix an appointment.</p>
</div>
<div class="col-md-4 text-center hidden-xs hidden-sm">
<i class="icon-superscript icon-huge"></i>
</div>

</div>
</div>
</div>
</div> -->

</div>

<div id="overlay"></div>

</div>
</div>
</body>
</html>
